:PROPERTIES:
:ID:       197f325b-2b2f-46bf-9ed3-6b692fc12b80
:END:
#+title: theory-and-reality

* Introduction

Note: this time this chapter was read using the following skimming techique:
1. read the section headings
2. read the first and last paragraphs
3. read the first sentence of each paragraph

I did get distracted here and there and read a little more.

In this chapter Peter Godfrey-Smith starts by briefly outlining the topic of the book: principally the attempts to answer the questions of what science is, how it works, and what, if anything, separates it from other forms of acquiring knowledge.
He primes the reader on the different forms these questions can take, whether relating to epistemology or metaphysics, are descriptive or normative, and where they relate to questions of realism and objectivity.
He describes three aspects of the approaches to these questions: empiricism, mathematics, and social organization, and mentions an example or argument for and against the importance of each aspect.
For empiricism: he mentions the example of John Snow hypothesizing that cholera spreads through drinking water and testing this by removing the handle of key water fountains, resulting in a reduction in the cholera outbreak in London.
As a counterexample, he mentions Pettenkofer drinking a vial of cholera and being fine - suggesting he had falsified the germ theory of disease, when really its empirical consequences simply weren't so straightforward.
For mathematics, he mentions the importance that it has had in physical science, but also mentions that very major developments in science have occurred without any formal mathematics.
For the social structure, he emphasizes the role of trust and authority in the passing on of knowledge, but subsequenly describes how social and empirical ideas in science can be reconciled as social structures making scientific communities especially receptive to empirical observations.

The last section of the chapter provides a brief history of different attitudes surrounding science from aristotle through medieval times, into the renaissance through Copernicus and Galileo, followed by the enlightenment and scientific revolution.
The aristotelian approach relied heavily on ideas regarding naturalness and purpose.
Copernicus used this naturalness principle to create a heliocentric model of the solar system, which was regarded as simplifyig and useful, but not objectively true.
Galileo argued for the objective truth of this model and attempted to explain it through both mathematics and experiment.
Kepler documented the movements of planets extensively and used this information to build on the copernican model by changing circular motion to elliptical.
Subsequently, Newton explained this in the form of a number of mathematical laws.
During this time the Scientific Revolution was occurring, and Boyle (among others) adopted ideas around causality into a mechanistic view of the universe.
Later, Linneaus extensively systematized biology laying the groundwork for Darwin, Mendel, and the germ theory of disease.
He mentions how much of the social philosophy in subsequent years was based on an effort to emulate these successes.
This section lays some of the groundwork regarding what we have historically considered to be science.

** Key takeaways

 - the questions about what science is, how it should be done, and whether there are other ways of acquiring knowledge are largely unanswered.
 - what we refer to as science has been uniquely successful, and shares some commonalities in its reliance on empiricism, mathematics and formal logic, and particular social structures.
 - 

* Logic Plus Empiricism


In this chapter Peter Godfrey-Smith summarizes the logical positivist/empiricist movment.

The logical empiricists had a view on epistemology based on the analytic-synthetic distinction, and the verfiability principle.
Analytic statements are inherently true or false, logical tautologies or contradictions.
Synthetic statements are statements about observations, and we can find them to be true or false based on what we observe.
The logical positivists argued that all a-priori knowledge is purely analytic, and therefore has no bearing on the observable universe by itself.
Knowledge about the universe requires synthetic truths, requiring observation.
The verifiability principle states that the meaning of a statement depends on its observable consequences - meaning that a statement is meaningful if and only if there is some way to check empirically whether it is true or false.
In effect this says that the only source of knowledge about the universe is experience.
Related concepts include the distinction between observational and theoretical language, inductive logic.

One critique of this approach came from Quine, who argued that it is not individual statements or theories which are verifiable, but only ever one's whole network of beliefs, that analytic claims can be revised by changing logical systems and potentially on the basis of observation (e.g. certain results from quantum physics suggesting a deductive rule is sometimes violated).

Another challenge came from scientific realism. The idea that science is concerned only with observables leads to the conclusion that any discussion about abstract entities (e.g. electrons, genes, etc.) is really just a discussion about their empirical consequences. PGS states that this is a mistake, and that science ca only be understood by treating much of it as describing hidden structures that give rise to observable phenomena. He does not defend this in detail here, but does so in later chapters.

** key takeaways


 - unlike e.g. Kant, positivists believed there are no a-priori synthetic statements (see example of euclidean geometry).
 - key errors of logical positivism included
   - inability to establish inductive logic
   - dismissed relevance of psychology or sociology to epistemology
   - verifiability principle lead to paradoxes (e.g. A & B is verifiable if A is verifiable)
   - inadequately accomodated holism
   - assertion that analytic claims can never be revised considered uncertain
   - dismissing/bracketing scientific realism


* Induction and Confirmation


Peter Godfrey-Smith explains several puzzles with the related questions of Induction, confirmation and explanatory inference.
The problem of induction is whether past observations can give us knowledge about future observations.
Confirmation is the more general question of whether observations of some specific cases can give us knowledge about more general cases.
The logical empiricists viewed these as the only forms of nondeductive inference, but there is also explanatory inference.
PGS uses the example of the hypothesis that a meteor hit the earth 65 million years ago, supported by the evidence of unusually high levels of certain minerals in the corresponding layers of the earth's crust.
The logical-empiricist framework of generalizations being supported by individual cases does not straighforwardly apply to this.
Logical empiricists argued that such cases could be broken down into sets of multiple generalizations to form confirmation. (this could be an exercise?)
Others argued the reverse - that confirmation and induction are special cases of explanatory inference.
A subset of induction is projection - inference not about all observable cases, but just about the next observable case.

PGS describes two logical empiricist suggestions for these problems: Carnap's probabilistic approach and Hempel's approach, which intended to resemble deductive logic.
Probabilistic approaches will be revisited in chapter 14, but it is mentioned that the attempt seemed increasingly disconnected from real science and eventually ran out of steam. 
The hypothetico-deductivist approach is that if some hypothesis logically implies some outcome, observing that outcome provides logical support for the hypothesis.
Besides the problem of holism, this runs into several problems (not all of which are listed here).
Similar to the criteron of testability in section 2.4, T -> T or s, where T and s are any statements at all. T or s can be checked by confirming s, therefore supporting T.
Situations like these became part of the criticism of logical empiricism - the use of abstract simplified hypotheticals which differ greatly from any real science being done. 
With regard to generalizations, one solution offered is that for each raven observed to be black, there are fewer unobserved ravens which could be non-black, and hence the generalization that all are black is more likely to be true.
This does not work for generalizations over infinite sets, and does not work for projection.
Hempel's approach to generalization was to state that any observation of a specific case lends support to the general case.
This leads to a problem: all ravens are black is equivalent to all nonblack things are not ravens.
This means that specific cases lending support to the statement include things like... the observation of a white shoe, since it is a nonblack thing which is not a raven.
Good suggested that the validity of this will depend on related contextual knowledge (TODO: revisit his example when clearheaded).
Another possibility is that it depends on the procedure for these observations (to be expanded on in chapter 14).
Briefly, if someone tells you they have a nonblack object behind their back, you may want to see if it is a raven. 
If they say they have a nonraven behind their back, subsequently revealing its color tells you nothing about the generalization.
In this view it is the potential of the observation to falsify which is relevant. 
The logical empiricists did not agree with these solutions, as they were hoping for an abstract, general connection between the general and specific case independent of contextual factors.

Another problem posed to these theories of inference is Goodman's riddle of induction.
An object is grue if it was observed before present day and is green, or if it is observed after present day and is blue.
The statement 'all emeralds are grue' is equally well supported by previous observations of green emeralds as 'all emeralds are green'.
Goodman's aim was to show that induction void of context is not possible.
Arguments that this is invalid because 'grue' is not a real property of objects turn out to be difficult to defend, due to difficulty in defining which properties are real.
Arguments from simplicity suffer a similar problem.

** Key takeaways

General theories
 - hypothetico-deductivisim: faces a variety of logic problems + holism

Early theories of confirmation/generalization:
 - 'ways to be wrong' approach - cannot explain projection (therefore useless) or infinite sets
 - Carnap's probabilistic theories (incomplete and not pragmatic)
 - Hempel's theories: indoor ornithology 
 - Good's solution : contextual
 - falsifiability solution: contextual
 
problems: 
 T -> T or s
 indoor ornithology, falsifiability, squares
 Goodman's riddle (grue and bleen)
 

* Popper: Conjecture and Refutation


This chapter describes the contributions of Karl Popper's contributions to philosophy of science. It can be summarized as stating that induction cannot give us knowledge about the world, but observation and deductive logic can. This results in two similar answers to the questions of demarcation and scientific practice.
For Popper, an idea is scientific only if some observation has the postential to refute it. 
In normal scientific practice, this refustation is the only role of observation.
An idea passing a test (an attempt to falsify it) does not increase our confidence in it in any way.
PGS likens this to a knight searching for a holy grail, the holy grail glows forever but there is an infinite set of nonholy grails which someday stop glowing, and the glow is the only way to distinguish them.
Popper believed that it is best for both the conjecture and the refutation to be made by the same person, lest they refuse to change their minds about the conjecture when someon else refutes them,

PGS then launches into a summary of the many criticisms leveled at popper's philosophy of science.
One of the major problems with falsificationism as a demarcation of science is holism.
Say you want to falsify the statement that iron bars expand when heated.
If you find what you believe to be an iron bar which contracts while heated, how do you know for sure that what you found is really iron?
The problem may be with the theory, or it may be with some auxillary assumption used in the measurement process.
A more nuanced way of describing falsificationism can be constructed by stating that rather than a particular idea being scientific, an idea can be treated in a scientific way by exposing it to empirical risk (through embedding it in a surrounding theoretical body).
This however requires us to have some confidence in the surrounding theoretical body - a possibility which Popper rejected.
For demarcation, this could be stated to be a matter of attributing the observation to the falisty of the conjecture being tested instead of auxillary assumptions, but popper's theory cannot provide an explanation of why this decision would be preferable.
Another problem for falsification is the fact that many theories do not state that some observation is impossible, only that it is unlikely.
These theories are then not falsifiable - and therefore not scientific - wrt. that observation.
Popper conceded that these can be falsified 'in practice' by extremely unlikely results, which is a departure from his pure deductivisim.

Popper's lack of induction form a problem for his theory of science.
PGS uses the example of building a brige, where we can try to use a tried and tested method that has withstood falsification, or a wholly new one.
Popper provides no basis for choosing one over the other, even though it is obvious which decision is the better one.
Popper attempted to patch this with 'corroboration'.
The difference being that corroboration indicated a past of empirical success, without predicting a future of empirical success (think a resume vs a letter of reccomendation).
This does not address the problem in any way.

PGS subsequently argues for a holistic way of using Popper's ideas, such that the scientific treatment of an idea is in building a theoretical framework which can be combined with induction to expose ideas to empirical risk.

** Key takeaways


 - lacking induction, Popper's theory cannot provide an epistemological basis for science
 - allowing induction enables us to expose ideas to epistemological risk (holistically)





